{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ready-typing",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "confidential-intermediate",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in /home/vinayak.t/.local/lib/python3.8/site-packages (2.0.0)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-19 19:22:36.057351: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-19 19:22:36.057380: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "!pip install emoji\n",
    "import emoji\n",
    "import joblib\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, SimpleRNN, Embedding\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "future-seeking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>French macaroon is so tasty</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>work is horrible</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am upset</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>throw the ball</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good joke</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>lets brunch some day</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>dance with me</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>she is a bully</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>she plays baseball</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>I like it when people smile</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0  1\n",
       "0    French macaroon is so tasty  4\n",
       "1               work is horrible  3\n",
       "2                     I am upset  3\n",
       "3                 throw the ball  1\n",
       "4                      Good joke  2\n",
       "..                           ... ..\n",
       "178         lets brunch some day  4\n",
       "179                dance with me  2\n",
       "180               she is a bully  3\n",
       "181           she plays baseball  1\n",
       "182  I like it when people smile  2\n",
       "\n",
       "[183 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('emoji_data.csv', header = None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hollywood-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary to MAP integers to emoji\n",
    "\n",
    "emoji_dict = {\n",
    "    0: \":red_heart:\",\n",
    "    1: \":baseball:\",\n",
    "    2: \":grinning_face_with_big_eyes:\",\n",
    "    3: \":disappointed_face:\",\n",
    "    4: \":fork_and_knife_with_plate:\"\n",
    "}\n",
    "\n",
    "def label_to_emoji(label):\n",
    "    return emoji.emojize(emoji_dict[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0634ddea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'❤️'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji.emojize(emoji_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "indoor-recipient",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[0].values\n",
    "Y = data[1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-oxide",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "buried-opposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('glove.6B.100d.txt', 'r', encoding = 'utf8')\n",
    "content = file.readlines()\n",
    "file.close()\n",
    "\n",
    "# content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "based-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = {}\n",
    "\n",
    "for line in content:\n",
    "    line = line.split()\n",
    "    embeddings[line[0]] = np.array(line[1:], dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "coordinate-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maxlen(data):\n",
    "    maxlen = 0\n",
    "    for sent in data:\n",
    "        maxlen = max(maxlen, len(sent))\n",
    "    return maxlen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "manual-maryland",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "word2index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "recovered-fortune",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[103, 104,   3, ...,   0,   0,   0],\n",
       "       [106,   3, 107, ...,   0,   0,   0],\n",
       "       [  1,   7, 108, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [ 14,   3,   5, ...,   0,   0,   0],\n",
       "       [ 14, 310,  26, ...,   0,   0,   0],\n",
       "       [  1,  24,  22, ...,   0,   0,   0]], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtokens = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "maxlen = get_maxlen(Xtokens)\n",
    "print(maxlen)\n",
    "#All tokens must be of same length so padding is done\n",
    "Xtrain = pad_sequences(Xtokens, maxlen = maxlen,  padding = 'post', truncating = 'post')\n",
    "Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94c30201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 3, 1, 2, 1, 4, 3, 4, 1, 3, 3, 2, 2, 4, 3, 2, 3, 3, 1, 3, 2,\n",
       "       2, 2, 0, 1, 0, 4, 2, 0, 2, 0, 0, 3, 4, 0, 2, 1, 3, 1, 0, 4, 0, 3,\n",
       "       0, 4, 2, 3, 4, 2, 2, 3, 0, 2, 2, 3, 2, 3, 2, 2, 3, 3, 0, 2, 3, 0,\n",
       "       2, 0, 0, 2, 3, 2, 4, 1, 3, 3, 0, 0, 3, 2, 0, 3, 0, 2, 2, 4, 2, 2,\n",
       "       0, 0, 2, 3, 0, 4, 2, 1, 2, 3, 3, 2, 3, 0, 3, 0, 2, 0, 2, 3, 4, 3,\n",
       "       1, 3, 4, 3, 2, 3, 3, 3, 1, 4, 4, 2, 2, 1, 1, 2, 3, 2, 3, 4, 2, 3,\n",
       "       0, 2, 0, 0, 4, 3, 4, 2, 3, 2, 3, 4, 2, 1, 2, 4, 3, 1, 3, 2, 3, 2,\n",
       "       2, 3, 3, 2, 4, 0, 0, 0, 3, 0, 0, 1, 1, 2, 2, 2, 0, 3, 2, 3, 3, 1,\n",
       "       2, 2, 4, 2, 3, 1, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "polyphonic-cannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain = to_categorical(Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-violin",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "intended-rapid",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 100\n",
    "embedding_matrix = np.zeros((len(word2index)+1, embed_size))\n",
    "\n",
    "for word, i in word2index.items():\n",
    "    embed_vector = embeddings[word]\n",
    "    embedding_matrix[i] = embed_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "weighted-relationship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
       "         0.      ],\n",
       "       [-0.046539,  0.61966 ,  0.56647 , ..., -0.37616 , -0.032502,\n",
       "         0.8062  ],\n",
       "       [-0.49886 ,  0.76602 ,  0.89751 , ..., -0.41179 ,  0.40539 ,\n",
       "         0.78504 ],\n",
       "       ...,\n",
       "       [-0.46263 ,  0.069864,  0.69095 , ..., -0.29174 ,  0.32041 ,\n",
       "         0.21202 ],\n",
       "       [ 0.073242,  0.11134 ,  0.62281 , ...,  0.53417 , -0.1646  ,\n",
       "        -0.27516 ],\n",
       "       [ 0.29019 ,  0.80497 ,  0.31187 , ..., -0.33603 ,  0.45998 ,\n",
       "        -0.11278 ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "homeless-single",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-19 19:22:47.746631: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-19 19:22:47.746680: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-19 19:22:47.746732: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ggn000720): /proc/driver/nvidia/version does not exist\n",
      "2022-08-19 19:22:47.747101: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim = len(word2index) + 1,\n",
    "              output_dim = embed_size,\n",
    "              input_length = maxlen,\n",
    "              weights = [embedding_matrix],\n",
    "              trainable = False\n",
    "             ),\n",
    "    \n",
    "    LSTM(units = 20, return_sequences = True),\n",
    "    LSTM(units = 4),\n",
    "    Dense(5, activation = 'softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "technical-possible",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 4s 14ms/step - loss: 1.5852 - accuracy: 0.3005\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5561 - accuracy: 0.3607\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5332 - accuracy: 0.3661\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.5128 - accuracy: 0.4098\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4928 - accuracy: 0.4372\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.4705 - accuracy: 0.4481\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.4385 - accuracy: 0.4863\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.4070 - accuracy: 0.4973\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.3652 - accuracy: 0.5027\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.3292 - accuracy: 0.5027\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2821 - accuracy: 0.5082\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.2353 - accuracy: 0.5301\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2032 - accuracy: 0.5246\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.1696 - accuracy: 0.5410\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.1309 - accuracy: 0.5574\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.0906 - accuracy: 0.5792\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0428 - accuracy: 0.6011\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0295 - accuracy: 0.6011\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.0013 - accuracy: 0.6066\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.9687 - accuracy: 0.6503\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.9249 - accuracy: 0.6339\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.8929 - accuracy: 0.6612\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.8592 - accuracy: 0.6995\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.8239 - accuracy: 0.6940\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.8283 - accuracy: 0.7049\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.7814 - accuracy: 0.6940\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7629 - accuracy: 0.7268\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7691 - accuracy: 0.6831\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7225 - accuracy: 0.7322\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6999 - accuracy: 0.7377\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6779 - accuracy: 0.7596\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.6656 - accuracy: 0.7650\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6463 - accuracy: 0.7705\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6321 - accuracy: 0.7760\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6155 - accuracy: 0.7760\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6028 - accuracy: 0.7869\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5925 - accuracy: 0.7978\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5826 - accuracy: 0.8033\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5677 - accuracy: 0.8087\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5572 - accuracy: 0.8306\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5464 - accuracy: 0.8361\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5344 - accuracy: 0.8361\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5205 - accuracy: 0.8470\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5086 - accuracy: 0.8579\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5005 - accuracy: 0.8579\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4911 - accuracy: 0.8579\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.4805 - accuracy: 0.8579\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.4714 - accuracy: 0.8579\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.4663 - accuracy: 0.8579\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5024 - accuracy: 0.8306\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6187 - accuracy: 0.7869\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7446 - accuracy: 0.7104\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8241 - accuracy: 0.6557\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6064 - accuracy: 0.7705\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5837 - accuracy: 0.8142\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4920 - accuracy: 0.8470\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4664 - accuracy: 0.8525\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4520 - accuracy: 0.8525\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.4370 - accuracy: 0.8579\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.4278 - accuracy: 0.8579\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4177 - accuracy: 0.8634\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4079 - accuracy: 0.8634\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3994 - accuracy: 0.8634\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3925 - accuracy: 0.8634\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3845 - accuracy: 0.8634\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3781 - accuracy: 0.8689\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3718 - accuracy: 0.8743\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3663 - accuracy: 0.8743\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3622 - accuracy: 0.8743\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3576 - accuracy: 0.8634\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3522 - accuracy: 0.8689\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3501 - accuracy: 0.8798\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3424 - accuracy: 0.8798\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3408 - accuracy: 0.8634\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3355 - accuracy: 0.8798\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3323 - accuracy: 0.8798\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3288 - accuracy: 0.8689\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3245 - accuracy: 0.8798\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3217 - accuracy: 0.8798\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3189 - accuracy: 0.8798\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3160 - accuracy: 0.8743\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.3129 - accuracy: 0.8798\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3099 - accuracy: 0.8852\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3073 - accuracy: 0.9071\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3049 - accuracy: 0.9180\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3019 - accuracy: 0.9016\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2994 - accuracy: 0.9071\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2930 - accuracy: 0.9180\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2904 - accuracy: 0.9071\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2872 - accuracy: 0.9016\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2853 - accuracy: 0.8907\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2830 - accuracy: 0.8907\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2812 - accuracy: 0.8907\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2793 - accuracy: 0.8907\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2777 - accuracy: 0.8907\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.2759 - accuracy: 0.8907\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.2742 - accuracy: 0.8907\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2726 - accuracy: 0.8907\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.2711 - accuracy: 0.8907\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2696 - accuracy: 0.8907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f45a819e0a0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, Ytrain, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "convertible-spider",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "[[0.01749783 0.01419746 0.44008014 0.5129961  0.01522854]\n",
      " [0.00212061 0.01984117 0.9352627  0.02559329 0.01718217]\n",
      " [0.00212061 0.01984117 0.9352627  0.02559329 0.01718217]\n",
      " [0.00204744 0.01584689 0.9343629  0.03388417 0.01385871]\n",
      " [0.00212061 0.01984117 0.9352627  0.02559329 0.01718217]\n",
      " [0.00212061 0.01984117 0.9352627  0.02559329 0.01718217]\n",
      " [0.00212061 0.01984117 0.9352627  0.02559329 0.01718217]\n",
      " [0.00212061 0.01984117 0.9352627  0.02559329 0.01718217]\n",
      " [0.00212061 0.01984117 0.93526274 0.02559329 0.01718217]\n",
      " [0.00212061 0.01984117 0.93526274 0.02559329 0.01718217]]\n",
      "[2, 3]\n",
      "😃\n",
      "😞\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_seq = tokenizer.texts_to_sequences(\"i eat food\")\n",
    "Xtest = pad_sequences(test_seq, maxlen = maxlen, padding = 'post', truncating = 'post')\n",
    "\n",
    "y_pred = model.predict(Xtest)\n",
    "print(y_pred)\n",
    "y_pred1 = np.argsort(y_pred, axis = 1)\n",
    "labels = list(y_pred1[0][-2:])\n",
    "print(list(y_pred1[0][-2:]))\n",
    "for i in labels:\n",
    "    print(label_to_emoji(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a36106d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(model):\n",
    "    # Save the trained weights\n",
    "    model.save_weights('models/model_weights.h5')\n",
    "\n",
    "    # Save the model architecture\n",
    "    with open('models/model_architecture.json', 'w') as f:\n",
    "        f.write(model.to_json())\n",
    "\n",
    "    # Save the tokenizer\n",
    "    with open('models/tokenizer.json', 'w') as f:\n",
    "        f.write(tokenizer.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fac4ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84af21ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
